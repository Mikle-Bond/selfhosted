version: "3.8"

volumes:
  caddy_conf: {}
  caddy_acme_root: {}
  local_ca: {}
  wireguard_data: {}
  dockerhosts: {}
  ntfy_data: {}
    # sqldata: {}
    # dnsconfig: {}
    # mosquitto_data: {}
    # mosquitto_logs: {}
  nextcloud:
    external: true
  nextcloud_data:
    external: true
  portainer_data: {}


networks:
  docker-socket-rw: {}
  docker-socket-ro: {}
  caddy:
    external: true
  dns:
    external: true

secrets:
  headscale-noise:
    file: ./secrets/headscale/noise.key
  headscale:
    file: ./secrets/headscale/private.key
  flame_password:
    file: ./secrets/flame/password.txt
  archivebox:
    file: ./secrets/archivebox/sonic.txt

x-lsio: &lsio
  environment:
    - PUID
    - PGID
    - TZ

x-lsio-dict: &lsiodict
  PUID:
  PGID:
  TZ:


x-default: &default
  restart: unless-stopped
  networks:
    - caddy

x-failed:
  labels:
    virtual.port: 8000
    caddy: 'import rproxy {{index .Labels "com.docker.compose.service"}} {{$$port:=index .Labels "virtual.port"}}{{upstreams $$port}}'
    caddy_4: forms.mbond.duckdns.org
    caddy_4.tls.dns: duckdns "{env.DUCKDNS_TOKEN_MBOND}"
    caddy_4.reverse_proxy: "* https://docs.google.com"
    caddy_4.reverse_proxy.header_up: "Host {http.reverse_proxy.upstream.hostport}"
    caddy_4.reverse_proxy.header_down: 'location \"^(.*https?://)([^/]+)(.*)$$\" \"$$1forms.mbond.duckdns.org$$3\"'
    caddy_4.reverse_proxy.header_down: "-cross-origin-opener-policy"

x-disabled:
  dockerhost:
    restart: unless-stopped
    build:
      context: build/caddy-l4
      args:
        - GOPROXY=https://goproxy.io,https://proxy.golang.org,direct
    network_mode: host
    links:
      - caddy:caddy

  qr2:
    <<: *default
    image: reg.${BASE_DOMAIN}/qr-code-generator/web:latest # ghcr.io/pjanczyk/qr-code-generator/web:latest
    # NB: compose files do not support building from git when buildx is used.
    # Thus, run as `DOCKER_BUILDX=0 docker compose build qr2`
    # NB: this build fails due to censoring ISP, use proxy
    build: "https://github.com/pjanczyk/qr-code-generator.git#:web"
    environment:
      QR-CODE-GENERATOR_BASE-URL: "https://qr2.${BASE_DOMAIN}"
      QR-CODE-GENERATOR_QR-CODE-SERVICE-ADDRESS: qr2-backend:5000
    expose:
      - "8000/tcp"
    depends_on:
      - qr2-backend
    labels:
      caddy: import rproxy qr2 "{{upstreams 8000}}"
      flame.type: app
      flame.name: QRcode Generator 2
      flame.url: "qr2.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=qr&size=0..32..700&format=png"
      homepage.name: QRcode 2
      homepage.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=qr&size=0..32..700&format=png"
      homepage.href: "https://qr2.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: Another QRcode Generator

  qr2-backend:
    <<: *default
    image: reg.${BASE_DOMAIN}/qr-code-generator/qr-code-service:latest
    build: "https://github.com/pjanczyk/qr-code-generator.git#:qr-code-service"
    expose:
      - "5000/tcp"


services:
  hosts:
    restart: unless-stopped
    image: jwilder/docker-gen
    command: -watch /input/docker.hosts.tmpl /output/docker.hosts
    volumes:
      - ./conf/hosts/:/input
      - dockerhosts:/output
      - /usr/share/zoneinfo:/usr/share/zoneinfo:ro
    environment:
      - TZ
      - DOCKER_HOST=tcp://docker-socket-proxy:2375
    depends_on:
      - docker-socket-proxy
    networks:
      - docker-socket-ro

  dns:
    restart: unless-stopped
    container_name: dns
    build: build/coredns
    image: reg.${BASE_DOMAIN}/coredns
    volumes:
      - dockerhosts:/data:ro
    command: |
      ash -c "cat > Corefile <<EOF && cat Corefile && /usr/bin/env coredns
      doc {
        hosts /data/docker.hosts
        log
      }
      EOF"
    networks:
      dns:
        ipv4_address: "169.254.0.53"


  portainer-socket:
    <<: *default
    networks:
      - docker-socket-rw
    image: tecnativa/docker-socket-proxy
    expose:
      - "2375/tcp"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - CONTAINERS=1
      - INFO=1
      - IMAGES=1
      - POST=1
      - NETWORKS=1
      - VOLUMES=1

  portainer:
    <<: *default
    networks:
      - caddy
      - docker-socket-rw
    image: portainer/portainer-ce:latest
    command: -H tcp://portainer-socket:2375
    depends_on:
      - portainer-socket
    container_name: portainer
    expose:
      - "8000/tcp"
      - "9000/tcp"
    volumes:
      - portainer_data:/data
    labels:
      caddy_1: import rproxy portainer "{{upstreams 9000}}"
      caddy_2: import rproxy edge "{{upstreams 8000}}"


  acme:
    <<: *default
    image: alpine
    command:
      - sh
      - -c
      - |
        cp /data/caddy/pki/authorities/local/root.crt /acme/
        apk add ca-certificates
        mkdir -p /usr/local/share/ca-certificates/
        cp /data/caddy/pki/authorities/local/*.crt /usr/local/share/ca-certificates/
        update-ca-certificates
        exec sleep infinity
    volumes:
      - ./data/caddy:/data:ro
      - caddy_acme_root:/acme
      - local_ca:/etc/ssl/certs
    labels:
      caddy: caddy
      caddy.acme_server:
      caddy.tls: internal
      #caddy.root: "* /data/caddy/pki/authorities/local/"
      #caddy.file_server: '"/*.crt"'


  test-ost:
    <<: *default
    image: reg.ter224.duckdns.org/caddy:${CADDY_VERSION:-latest}
    environment:
      DOCKER_HOST: tcp://docker-socket-proxy:2375
      CADDY_DOCKER_LABEL_PREFIX: ost
      CADDY_INGRESS_NETWORKS: caddy
    volumes:
      - caddy_acme_root:/acme/:ro
      - ./data/openspeedtest:/data
      - ./static/Speed-Test:/app:ro
    labels:
      ost_0.acme_ca: https://caddy/acme/local/directory
      ost_0.acme_ca_root: /acme/root.crt
      ost_0.debug:

      ost_1: ":3000"
      ost_1.header: "-Server"
      ost_1.log.format: console
      ost_1.log.level: DEBUG
      ost_1.reverse_proxy.transport: http
      ost_1.reverse_proxy.transport.tls_trusted_ca_certs: /acme/root.crt
      ost_1.reverse_proxy.transport.tls_server_name: "test-ost"
      ost_1.reverse_proxy: "https://127.0.0.1:443"
      ost_1.reverse_proxy.header_up: "Host test-ost"
      ost_1.reverse_proxy.header_down: "-Server"
      ost_1.reverse_proxy.flush_interval: -1
      ost_1.reverse_proxy.buffer_requests:
      ost_1.reverse_proxy.buffer_responses:
      ost_1.reverse_proxy.max_buffer_size: "55MiB"

      ost_2: "test-ost"
      ost_2.log.format: console
      ost_2.log.level: DEBUG
      ost_2.tls.alpn: "h1 http/1.1"
      ost_2.tls.ca: https://caddy/acme/local/directory
      ost_2.tls.ca_root: /acme/root.crt
      ost_2.header.Cache-Control: '"no-store, no-cache, max-age=0, no-transform"'
      ost_2.root: "* /app/"
      ost_2.file_server.hide: .git
      ost_2.header.Access-Control-Allow-Origin: "*"
      ost_2.header.Access-Control-Allow-Methods: '"GET, POST, OPTIONS"'
      ost_2.header.Access-Control-Allow-Headers: 'Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With'
      ost_2.@cors.method: OPTIONS
      ost_2.@cors.host: "test-ost.${BASE_DOMAIN}"
      ost_2.handle: "@cors"
      ost_2.handle.header.Access-Control-Allow-Credentials: "true"
      ost_2.handle.header.Access-Control-Allow-Origin: "{header.origin}"
      ost_2.handle.respond: "204"

      caddy: "test-ost.${BASE_DOMAIN}"
      #caddy.reverse_proxy.transport: http
      #caddy.reverse_proxy.transport.tls_trusted_ca_certs: /data/caddy/pki/authorities/local/root.crt
      #caddy.reverse_proxy: "https://test-ost"
      #caddy.reverse_proxy.header_up: "Host {upstream_hostport}"
      caddy.reverse_proxy: "{{upstreams 3000}}"
      #caddy.reverse_proxy.flush_interval: -1
      #caddy.reverse_proxy.buffer_requests:
      #caddy.reverse_proxy.buffer_responses:
      #caddy.reverse_proxy.max_buffer_size: "55MiB"


  caddy:
    build:
      context: build/caddy
      args:
        - GOPROXY=https://goproxy.io,https://proxy.golang.org,direct
    image: reg.ter224.duckdns.org/caddy:${CADDY_VERSION:-latest}
    container_name: caddy
    restart: unless-stopped
    networks:
      caddy:
      dns:
        ipv4_address: "169.254.0.100"
    environment:
      - CADDY_INGRESS_NETWORKS=caddy
      - CADDY_DOCKER_CADDYFILE_PATH=/config/Caddyfile.globals
      - CADDY_DOCKER_PROCESS_CADDYFILE=true
      - BASE_DOMAIN
    env_file: secrets/caddy/credentials.env # TODO
    ports:
      - published: 10443
        target: 443
          #mode: host
      - published: 10080
        target: 80
          #mode: host
      - "443:443/udp"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock # TODO
      - ./conf/caddy:/config
      - ./data/caddy:/data
      - ./static/qrazybox:/qrazybox
      - ./static/www:/www
      # /home/launcher/updates:/launcher
      - nextcloud:/nextcloud/var/www/html
      - nextcloud_data:/nextcloud/var/nextdata
    labels:
      caddy_0: "${BASE_DOMAIN}"
      caddy_0.redir: "https://flame.${BASE_DOMAIN}"
      #caddy_0.import: tlsdns
      #caddy_0.root: "* /www"
      #caddy_0.file_server:
      #caddy_0.templates:

      caddy_1: "qrazybox.${BASE_DOMAIN}"
      caddy_1.import: tlsdns
      caddy_1.root: "* /qrazybox/"
      caddy_1.tls.alpn: h2 h3
      caddy_1.file_server.hide: .git

      caddy_2: mbond.duckdns.org
      caddy_2.tls.dns: duckdns "{env.DUCKDNS_TOKEN_MBOND}"
      caddy_1.tls.alpn: h2 h3
      caddy_2.respond: "* TBD 200"
      caddy_2.log:


  dashmachine:
    <<: *default
    image: rmountjoy/dashmachine
    expose:
      - "5000/tcp"
    volumes:
      - ./data/dashmachine:/dashmachine/dashmachine/user_data
    labels:
      caddy: import rproxy dashmachine "{{upstreams 5000}}"
      flame.type: app
      flame.category: Homepages
      flame.name: DashMachine
      flame.url: "dashmachine.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=dashmachine:5000&size=0..32..700&format=png"
      homepage.name: DashMachine
      homepage.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=dashmachine:5000&size=0..32..700&format=png"
      homepage.href: "https://dashmachine.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: DashMachine homepage


  flame: &flame
    <<: *default
    image: pawelmalak/flame
      # TODO: point it to docker-socket-proxy
      # TODO: check out https://github.com/GeorgeSG/flame
      # TODO: also https://github.com/pawelmalak/flame/pull/396
    depends_on:
      - iconserver
      - docker-socket-proxy
    volumes:
      - ./data/flame:/app/data
      # /var/run/docker.sock:/var/run/docker.sock:ro
    expose:
      - "5005/tcp"
    labels:
      caddy: import rproxy flame "{{upstreams 5005}}"
      plugsy.name: flame
      plugsy.category: TEST
      plugsy.icon: "@styled-icons/feather/Database"
      plugsy.link: "https://flame.${BASE_DOMAIN}"
    secrets:
      - flame_password
    environment:
      # TODO: Password seems to be ignored, when passed as secret sometimes
      - PASSWORD=dummy
      - PASSWORD_FILE=/run/secrets/flame_password


  fdarveau-flame:
    <<: *flame
    image: ghcr.io/fdarveau/flame:2022-08-09
    volumes:
      - ./data/fdarveau-flame:/app/data
    labels:
      caddy: import rproxy fdarveau-flame "{{upstreams 5005}}"
      flame.type: app
      flame.category: Homepages
      flame.name: fdarveau-flame
      flame.url: "fdarveau-flame.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=fdarveau-flame:5005&size=0..32..700&format=png"


  georgesg-flame:
    <<: *flame
    image: georgesg/flame
    volumes:
      - ./data/georgesg-flame:/app/data
    labels:
      caddy: import rproxy georgesg-flame "{{upstreams 5005}}"
      flame.type: app
      flame.category: Homepages
      flame.name: georgesg-flame
      flame.url: "georgesg-flame.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=georgesg-flame:5005&size=0..32..700&format=png"


  registry:
    <<: *default
    image: registry:2
    container_name: registry
    expose:
      - "5000/tcp"
    volumes:
      - ./data/registry:/var/lib/registry
    labels:
      caddy: import auth_rproxy reg "{{upstreams 5000}}"


  registry-ui:
    <<: *default
    image: joxit/docker-registry-ui:latest
    depends_on:
      - registry
    expose:
      - "80/tcp"
    environment:
      - DELETE_IMAGES=false
      - REGISTRY_TITLE=ter224 Private Docker Registry
      - REGISTRY_URL=https://reg.${BASE_DOMAIN}
      - NGINX_PROXY_PASS_URL=http://registry:5000
      - SINGLE_REGISTRY=true
    labels:
      caddy: import rproxy registry "{{upstreams 80}}"
      flame.type: app
      flame.category: WebUIs
      flame.name: Docker Regisry UI
      flame.url: "registry.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=registry-ui:80&size=0..32..700&format=png"
      homepage.name: Docker Regisry UI
      homepage.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=registry-ui:80&size=0..32..700&format=png"
      homepage.href: "https://registry.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: Custom UI for private Docker registry


  whoami:
    <<: *default
    image: jwilder/whoami


  echo-server:
    restart: "no"
    image: itzg/web-debug-server # ealen/echo-server # mendhak/http-https-echo:26 # greenstatic/echo-ip
    environment: []
      #BIND: 192.168.196.158:80
    network_mode: host
    container_name: echo-server

  test:
    <<: *default
    image: mendhak/http-https-echo:26 # greenstatic/echo-ip
    labels:
      caddy: import rproxy test "{{upstreams 8080}}"


  headscale:
    <<: *default
    image: headscale/headscale:0.16.2
    command: headscale serve
    expose:
      - "80/tcp"
      - "9090/tcp" # metrics
      - "50443/tcp" # grpc
    volumes:
      - ./conf/headscale:/etc/headscale
      - ./data/headscale:/var/headscale
    secrets:
      - headscale # /var/secrets/headscale
      - headscale-noise
    labels:
      caddy: "headscale.${BASE_DOMAIN}"
      caddy.@hs-other.host: "headscale.${BASE_DOMAIN}"
      caddy.@hs-options.host: "headscale.${BASE_DOMAIN}"
      caddy.@hs-options.method: OPTIONS

      caddy.0_import: tlsdns

      caddy.1_handle: "@hs-options"
      caddy.1_handle.header.Access-Control-Allow-Origin: "https://ui.headscale.${BASE_DOMAIN}"
      caddy.1_handle.header.Access-Control-Allow-Headers: "*"
      caddy.1_handle.header.Access-Control-Allow-Methods: '"POST, GET, OPTIONS, DELETE"'
      caddy.1_handle.respond: "204"

      #caddy.2_handle_path: /grpc
      #caddy.2_handle_path.reverse_proxy: "{{upstreams grpc 50443}}"

      caddy.8_handle: /metrics
      caddy.8_handle.import: auth
      caddy.8_handle.reverse_proxy: "{{upstreams 9090}}"

      caddy.9_handle: "@hs-other"
      caddy.9_handle.reverse_proxy: "{{upstreams 80}}"
      caddy.9_handle.reverse_proxy.header_down_1: "Access-Control-Allow-Origin https://ui.headscale.${BASE_DOMAIN}"
      caddy.9_handle.reverse_proxy.header_down_2: "Access-Control-Allow-Headers *"
      caddy.9_handle.reverse_proxy.header_down_3: 'Access-Control-Allow-Methods "POST, GET, OPTIONS, DELETE"'


  headscale-ui:
    <<: *default
    image: ghcr.io/gurucomputing/headscale-ui:2022.11.05-beta
    expose:
      - "80/tcp"
    labels:
      caddy: import rproxy ui.headscale "{{upstreams 80}}"
      flame.type: app
      flame.category: WebUIs
      flame.name: Headscale
      flame.url: "https://ui.headscale.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=tailscale.com&size=0..32..700&format=png"


  iconserver:
    <<: *default
    #image: matthiasluedtke/iconserver
    build: https://github.com/mat/besticon.git#master
    image: reg.${BASE_DOMAIN}/iconserver
    volumes:
      - local_ca:/etc/ssl/certs:ro
    environment:
      - PORT=80
      - TZ
      - SERVER_MODE=download
      - MAX_ICON_SIZE=800
    expose:
      - "80/tcp"
    labels:
      caddy: import rproxy iconserver "{{upstreams 80}}"
      flame.type: app
      flame.category: Tools
      flame.name: Icon Server
      flame.url: "https://iconserver.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=iconserver&size=0..32..700&format=png"


  favicon:
    <<: *default
    build: build/favicon_proxy
    volumes:
      - ./conf/favicon:/app/conf
      # local_ca:/etc/ssl/certs:ro
      - caddy_acme_root:/acme/:ro
    environment:
      - PORT=80
      - TZ
      - NODE_EXTRA_CA_CERTS=/acme/root.crt
    expose:
      - "80/tcp"
    labels:
      caddy: import rproxy favicon "{{upstreams 80}}"
      flame.type: app
      flame.category: Tools
      flame.name: Favicon Proxy
      flame.url: "https://favicon.${BASE_DOMAIN}/"
      flame.icon: "https://img.icons8.com/material-outlined/48/null/globe--v1.png"


  openspeedtest:
    <<: *default
    image: openspeedtest/latest
    expose:
      - "3000/tcp"
    labels:
      caddy: "openspeedtest.${BASE_DOMAIN}"
      #caddy.tls.alpn: "h1 http/1.1"
      #caddy.@tests.path: "/upload*"
      #caddy.@tests.path: "/downloading*"
      #caddy.reverse_proxy.transport: "http"
      #caddy.reverse_proxy.transport.compression: "off"
      #caddy.reverse_proxy.transport.versions: "1.1"
      #caddy.log.format: console
      #caddy.reverse_proxy.transport.dial_timeout: "1m"
      #caddy.reverse_proxy.transport.max_response_header: "100MiB"
      # NB: https://github.com/openspeedtest/Speed-Test/issues/4#issuecomment-1229157193
      # It is said that some combination of these is needed...
      caddy.reverse_proxy: "{{upstreams 3000}}"
      caddy.reverse_proxy.flush_interval: "-1"
      caddy.reverse_proxy.buffer_requests:
      caddy.reverse_proxy.buffer_responses:
      caddy.reverse_proxy.max_buffer_size: "35MiB"
      #caddy.reverse_proxy: "{{upstreams 3000}}"
      #caddy.request_body.max_size: "100MiB"
      flame.type: app
      flame.category: Tools
      flame.name: OpenSpeedTest
      flame.url: "https://openspeedtest.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=openspeedtest:3000&size=0..32..700&format=png"
      homepage.name: OpenSpeedTest
      homepage.icon: openspeedtest
      homepage.href: "https://openspeedtest.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: Opensource speed measurement tool


  ntfy:
    <<: *default
    image: binwiederhier/ntfy:v1.27.2
    command: serve
    volumes:
      - ntfy_data:/var/cache/ntfy
    expose:
      - "80/tcp"
    environment:
      - NTFY_BEHIND_PROXY=true
    labels:
      caddy: import rproxy ntfy "{{upstreams 80}}"
      flame.type: app
      flame.category: Tools
      flame.name: NTFY
      flame.url: "https://ntfy.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=ntfy&size=0..32..700&format=png"


  zerotier:
    <<: *default
    image: dec0dos/zerotier-controller:latest
    volumes:
      - ./data/zerotier:/var/lib/zerotier-one
    expose:
      - "9993/tcp"


  zero-ui:
    <<: *default
    image: dec0dos/zero-ui:latest
    depends_on:
      - zerotier
    volumes:
      - ./data/zerotier:/var/lib/zerotier-one
      - ./data/zero-ui:/app/backend/data
    environment:
      - ZU_CONTROLLER_ENDPOINT=http://zerotier:9993/
      - ZU_SECURE_HEADERS=true
      - ZU_DEFAULT_USERNAME=admin
      - ZU_DEFAULT_PASSWORD=zero-ui
    expose:
      - "4000"
    labels:
      caddy: import rproxy zt "{{upstreams 4000}}"
      flame.type: app
      flame.category: WebUIs
      flame.name: ZeroTier
      flame.url: "https://zt.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=my.zerotier.com&size=0..32..700&format=png"


  ascii:
    <<: *default
    build: https://github.com/hugomd/ascii-live.git
    image: reg.${BASE_DOMAIN}/ascii-live:latest
    expose:
      - "8080/tcp"
    labels:
      caddy: import rproxy ascii "{{upstreams 8080}}"


  vaultwarden:
    <<: *default
    image: vaultwarden/server:latest
    expose:
      - "80/tcp"
    volumes:
      - ./data/vaultwarden:/data
    labels:
      caddy: import rproxy vaultwarden "{{upstreams 80}}"
      flame.type: app
      flame.category: WebUIs
      flame.name: Bitwarden
      flame.url: "https://vaultwarden.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=vaultwarden&size=0..32..700&format=png"


  snapdrop:
    <<: *default
    <<: *lsio
    image: lscr.io/linuxserver/snapdrop:latest
    volumes:
      - ./data/snapdrop:/config
        # TODO: that's not a config folder, bro...
    expose:
      - "80/tcp"
    labels:
      caddy: import rproxy snapdrop "{{upstreams 80}}"
      flame.type: app
      flame.category: Tools
      flame.name: Snapdrop
      flame.url: "https://snapdrop.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=snapdrop&size=0..32..700&format=png"


  homepage:
    <<: *default
    image: ghcr.io/benphelps/homepage:latest
    expose:
      - "3000/tcp"
    environment:
      - TZ
      - PUID
      - PGID
      - DOCKER_HOST=docker-socket-proxy:2375
        # TODO: is this the setting, or the one in /app/config/docker.yaml?
    depends_on:
      - docker-socket-proxy
    volumes:
      - ./data/homepage:/app/config
    labels:
      caddy: import rproxy homepage "{{upstreams 3000}}"
      flame.type: app
      flame.category: Homepages
      flame.name: Homepage
      flame.url: "https://homepage.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=homepage:3000&size=0..32..700&format=png"


  netdata:
    <<: *default
    image: netdata/netdata:stable
    hostname: "netdata.${BASE_DOMAIN}"
    cap_add:
      - SYS_PTRACE
    security_opt:
      - apparmor:unconfined
    environment:
      - TZ
      - PGID
      - PUID
      - DO_NOT_TRACK=1
      - DOCKER_HOST=docker-socket-proxy:2375
    depends_on:
      - docker-socket-proxy
    volumes:
      - ./conf/netdata:/etc/netdata
      - ./data/netdata/lib:/var/lib/netdata
      - ./data/netdata/cache:/var/cache/netdata
        # TODO: maybe move cache to volume
      - /etc/passwd:/host/etc/passwd:ro
      - /etc/group:/host/etc/group:ro
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /etc/os-release:/host/etc/os-release:ro
    expose:
      - "19999/tcp"
    labels:
      caddy: import rproxy netdata "{{upstreams 19999}}"
      flame.type: app
      flame.category: Tools
      flame.name: Netdata
      flame.url: "https://netdata.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=netdata:19999&size=0..32..700&format=png"


  diun:
    <<: *default
    build: build/diun
    volumes:
      - ./data/diun:/data
      - ./conf/diun:/conf
    environment:
      S6_KEEP_ENV: 1
      <<: *lsiodict

      LOG_LEVEL: info
      LOG_JSON: "false"
      DIUN_WATCH_WORKERS: 20
      DIUN_WATCH_SCHEDULE: "0 */6 * * *"
      DIUN_PROVIDERS_DOCKER: "true"
      DIUN_PROVIDERS_DOCKER_ENDPOINT: tcp://docker-socket-proxy:2375
      DIUN_PROVIDERS_DOCKER_WATCHBYDEFAULT: "true"

      DIUN_NOTIF_SCRIPT_CMD: /conf/notify.sh
      NTFY_URL: "http://ntfy/diun"
    depends_on:
      - docker-socket-proxy

    labels:
      diun.enable: "true"


  svgomg:
    <<: *default
    build: build/svgomg
    command: [] # WUT?
    image: reg.${BASE_DOMAIN}/svgomg:latest
    expose:
      - "8080/tcp"
    labels:
      caddy: import rproxy svgomg "{{upstreams 8080}}"
      flame.type: app
      flame.category: Tools
      flame.name: SVGOMG
      flame.url: "https://svgomg.${BASE_DOMAIN}/"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=svgomg:8080&size=0..32..700&format=png"
      homepage.name: SVGOMG
      homepage.icon: SVGOMG
      homepage.href: "https://svgomg.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: SVG optimizations tool

  qr:
    <<: *default
    image: bizzycolah/qrcode-generator:latest
    expose:
      - "80/tcp"
    labels:
      caddy: import rproxy qr "{{upstreams 80}}"
      flame.type: app
      flame.category: Tools
      flame.name: QRcode Generator
      flame.url: "qr.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=qr&size=0..32..700&format=png"
      homepage.name: QRcode
      homepage.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=qr&size=0..32..700&format=png"
      homepage.href: "https://qr.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: QRcode Generator


  docker-socket-proxy:
    <<: *default
    networks:
      - caddy
      - docker-socket-ro
    image: tecnativa/docker-socket-proxy
    expose:
      - "2375/tcp"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - CONTAINERS=1
      - IMAGES=1
      - INFO=1


  deck-chores-socket:
    <<: *default
    networks:
      - docker-socket-rw
    image: tecnativa/docker-socket-proxy
    expose:
      - "2375/tcp"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - CONTAINERS=1
      - IMAGES=1
      - POST=1
      - EXEC=1


  deck-chores:
    <<: *default
    networks:
      - docker-socket-rw
    depends_on:
      - deck-chores-socket
    image: funkyfuture/deck-chores:1
    environment:
      TIMEZONE: ${TZ}
      DOCKER_HOST: tcp://deck-chores-socket:2375
      DEFAULT_FLAGS: service


  archivebox:
    # Usage:
    #     docker-compose run archivebox init --setup
    #     docker-compose up
    #     echo "https://example.com" | docker-compose run archivebox archivebox add
    #     docker-compose run archivebox add --depth=1 https://example.com/some/feed.rss
    #     docker-compose run archivebox config --set PUBLIC_INDEX=True
    #     docker-compose run archivebox help
    # Documentation:
    #     https://github.com/ArchiveBox/ArchiveBox/wiki/Docker#docker-compose
    <<: *default
    # image: archivebox/archivebox:master
    # NB: temporary override image, see https://github.com/ArchiveBox/ArchiveBox/issues/991
    # IMAGE: turian/archivebox:kludge-984-UTF8-bug
    build:
      context: build/patch_entrypoint
      args:
        IMAGE: archivebox/archivebox:dev # sha-8a96563
        ENTRYPOINT: "dumb-init -- /app/bin/docker_entrypoint.sh"
    command: server --quick-init 0.0.0.0:3000
    environment:
      - ALLOWED_HOSTS=*
      - MEDIA_MAX_SIZE=750m
      - SEARCH_BACKEND_ENGINE=sonic
      - SEARCH_BACKEND_HOST_NAME=sonic
      - SEARCH_BACKEND_PASSWORD__FILE=/run/secrets/archivebox
    secrets:
      - archivebox
    volumes:
      - ./data/archivebox/archive:/data
    healthcheck:
      test: curl --silent http://localhost:3000
      interval: 1m30s
      timeout: 20s
      retries: 15
      start_period: 40s
    labels:
      caddy: import rproxy archivebox "{{upstreams 3000}}"
      flame.type: app
      flame.category: Tools
      flame.name: ArchiveBox
      flame.url: "archivebox.${BASE_DOMAIN}"
      flame.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=archivebox:3000&size=0..32..700&format=png"
      homepage.name: ArchiveBox
      homepage.icon: "http://iconserver.${BASE_DOMAIN}/icon?url=archivebox:3000&size=0..32..700&format=png"
      homepage.href: "https://archivebox.${BASE_DOMAIN}"
      homepage.group: Docker services
      homepage.description: Web Archiever

  sonic:
    <<: *default
    build:
      context: build/patch_entrypoint
      args:
        IMAGE: valeriansaliou/sonic:v1.3.0
        ENTRYPOINT: sonic
    command: "-c /etc/sonic.cfg"
    expose:
      - 1491
    environment:
      - SEARCH_BACKEND_PASSWORD__FILE=/run/secrets/archivebox
    secrets:
      - archivebox
    volumes:
      - ./conf/archivebox/sonic.cfg:/etc/sonic.cfg:ro
      - ./data/archivebox/sonic:/var/lib/sonic/store


  # # Example: Run scheduled imports in a docker instead of using cron on the
  # # host machine, add tasks and see more info with archivebox schedule --help
  # scheduler:
  #   image: archivebox/archivebox:latest
  #   command: schedule --foreground --every=day --depth=1 'https://getpocket.com/users/USERNAME/feed/all'
  #   environment:
  #     - USE_COLOR=True
  #     - SHOW_PROGRESS=False
  #   volumes:
  #     - ./data:/data

  # # Example: run all your ArchiveBox traffic through a WireGuard VPN tunnel
  # wireguard:
  #   image: linuxserver/wireguard
  #   network_mode: 'service:archivebox'
  #   cap_add:
  #     - NET_ADMIN
  #     - SYS_MODULE
  #   sysctls:
  #     - net.ipv4.conf.all.rp_filter=2
  #     - net.ipv4.conf.all.src_valid_mark=1
  #   volumes:
  #     - /lib/modules:/lib/modules
  #     - ./wireguard.conf:/config/wg0.conf:ro

  # # Example: Run PYWB in parallel and auto-import WARCs from ArchiveBox
  # pywb:
  #   image: webrecorder/pywb:latest
  #   entrypoint: /bin/sh 'wb-manager add default /archivebox/archive/*/warc/*.warc.gz; wayback --proxy;'
  #   environment:
  #     - INIT_COLLECTION=archivebox
  #   ports:
  #     - 8080:8080
  #   volumes:
  #     ./data:/archivebox
  #     ./data/wayback:/webarchive


